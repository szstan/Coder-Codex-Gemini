# CCG-MCP 配置文件示例
# 请复制此文件到 ~/.ccg-mcp/config.toml 并填入你的配置

[coder]
# Coder 工具可配置任意支持 Claude Code API 的模型后端
# 推荐使用 GLM-4.7 作为参考案例，也可选用其他模型（如 Minimax、DeepSeek 等）

# API 认证（必填）
# GLM 示例：从智谱 AI 平台获取 https://open.bigmodel.cn
api_token = "your-api-token"

# API 地址（必填，需支持 Claude Code API 协议）
# GLM 示例：
base_url = "https://open.bigmodel.cn/api/anthropic"

# 模型名称（可选，默认 glm-4.7）
model = "glm-4.7"

# 额外环境变量（建议保留）
# 可以添加任何需要传递给 Claude CLI 的环境变量
[coder.env]
# 禁用非必要的网络流量（遥测等），建议保持开启
CLAUDE_CODE_DISABLE_NONESSENTIAL_TRAFFIC = "1"

# Codex 配置（可选）
# 一般不需要配置，Codex 工具会使用 codex CLI 自己的配置
# 如需在调用时覆盖模型，可通过 MCP 工具的 model 参数指定
# 示例：调用时传入 model="o1"
